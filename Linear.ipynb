{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.au</td>\n",
       "      <td>0.349943</td>\n",
       "      <td>0.130225</td>\n",
       "      <td>1784.420446</td>\n",
       "      <td>2002.650192</td>\n",
       "      <td>3806.485316</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>-113.596742</td>\n",
       "      <td>121.557302</td>\n",
       "      <td>-19.158825</td>\n",
       "      <td>...</td>\n",
       "      <td>8.810668</td>\n",
       "      <td>-3.667367</td>\n",
       "      <td>5.751690</td>\n",
       "      <td>-5.162761</td>\n",
       "      <td>0.750947</td>\n",
       "      <td>-1.691937</td>\n",
       "      <td>-0.409954</td>\n",
       "      <td>-2.300208</td>\n",
       "      <td>1.219928</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.au</td>\n",
       "      <td>0.340983</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>1529.835316</td>\n",
       "      <td>2038.617579</td>\n",
       "      <td>3548.820207</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>-207.556796</td>\n",
       "      <td>124.006717</td>\n",
       "      <td>8.930562</td>\n",
       "      <td>...</td>\n",
       "      <td>5.376802</td>\n",
       "      <td>-2.239119</td>\n",
       "      <td>4.216963</td>\n",
       "      <td>-6.012273</td>\n",
       "      <td>0.936109</td>\n",
       "      <td>-0.716537</td>\n",
       "      <td>0.293875</td>\n",
       "      <td>-0.287431</td>\n",
       "      <td>0.531573</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.au</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>1552.481958</td>\n",
       "      <td>1747.165985</td>\n",
       "      <td>3040.514948</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>-90.754394</td>\n",
       "      <td>140.459907</td>\n",
       "      <td>-29.109965</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789265</td>\n",
       "      <td>-8.905224</td>\n",
       "      <td>-1.083720</td>\n",
       "      <td>-9.218359</td>\n",
       "      <td>2.455805</td>\n",
       "      <td>-7.726901</td>\n",
       "      <td>-1.815724</td>\n",
       "      <td>-3.433434</td>\n",
       "      <td>-2.226821</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.au</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>0.141191</td>\n",
       "      <td>1070.119953</td>\n",
       "      <td>1596.333948</td>\n",
       "      <td>2185.028454</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>-199.431144</td>\n",
       "      <td>150.099218</td>\n",
       "      <td>5.647594</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087676</td>\n",
       "      <td>-2.476420</td>\n",
       "      <td>-1.073890</td>\n",
       "      <td>-2.874777</td>\n",
       "      <td>0.780976</td>\n",
       "      <td>-3.316932</td>\n",
       "      <td>0.637981</td>\n",
       "      <td>-0.619690</td>\n",
       "      <td>-3.408233</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.au</td>\n",
       "      <td>0.308590</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>1835.494603</td>\n",
       "      <td>1748.362448</td>\n",
       "      <td>3580.945013</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>-160.266031</td>\n",
       "      <td>126.198800</td>\n",
       "      <td>-35.605448</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806385</td>\n",
       "      <td>-6.934122</td>\n",
       "      <td>-7.558619</td>\n",
       "      <td>-9.173552</td>\n",
       "      <td>-4.512166</td>\n",
       "      <td>-5.453538</td>\n",
       "      <td>-0.924162</td>\n",
       "      <td>-4.409333</td>\n",
       "      <td>-11.703781</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00000.au     0.349943  0.130225        1784.420446   \n",
       "1  blues.00001.au     0.340983  0.095918        1529.835316   \n",
       "2  blues.00002.au     0.363603  0.175573        1552.481958   \n",
       "3  blues.00003.au     0.404779  0.141191        1070.119953   \n",
       "4  blues.00004.au     0.308590  0.091563        1835.494603   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         2002.650192  3806.485316            0.083066 -113.596742   \n",
       "1         2038.617579  3548.820207            0.056044 -207.556796   \n",
       "2         1747.165985  3040.514948            0.076301  -90.754394   \n",
       "3         1596.333948  2185.028454            0.033309 -199.431144   \n",
       "4         1748.362448  3580.945013            0.101500 -160.266031   \n",
       "\n",
       "        mfcc2      mfcc3  ...    mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0  121.557302 -19.158825  ...  8.810668 -3.667367  5.751690 -5.162761   \n",
       "1  124.006717   8.930562  ...  5.376802 -2.239119  4.216963 -6.012273   \n",
       "2  140.459907 -29.109965  ...  5.789265 -8.905224 -1.083720 -9.218359   \n",
       "3  150.099218   5.647594  ...  6.087676 -2.476420 -1.073890 -2.874777   \n",
       "4  126.198800 -35.605448  ... -2.806385 -6.934122 -7.558619 -9.173552   \n",
       "\n",
       "     mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  label  \n",
       "0  0.750947 -1.691937 -0.409954 -2.300208   1.219928  blues  \n",
       "1  0.936109 -0.716537  0.293875 -0.287431   0.531573  blues  \n",
       "2  2.455805 -7.726901 -1.815724 -3.433434  -2.226821  blues  \n",
       "3  0.780976 -3.316932  0.637981 -0.619690  -3.408233  blues  \n",
       "4 -4.512166 -5.453538 -0.924162 -4.409333 -11.703781  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(genre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid=X_test[100:]\n",
    "y_valid=y_test[100:]\n",
    "X_test=X_test[:100]\n",
    "y_test=y_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=26, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1=nn.Linear(X_train.shape[2],256)\n",
    "        self.fc2=nn.Linear(256,128)\n",
    "        self.fc3=nn.Linear(128,64)\n",
    "        self.fc4=nn.Linear(64,n_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x=F.softmax(self.fc4(x))\n",
    "        return x\n",
    "model_scratch = Net()\n",
    "print (model_scratch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=0.001)\n",
    "#optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion,  save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "\n",
    "        for i in range(len(loaders['X_train'][1])):\n",
    "            # move to GPU\n",
    "            \n",
    "            data, target = loaders['X_train'], loaders['y_train']\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            \n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data.float())\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.long())\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss = train_loss + (1 / (i + 1)) * (loss.data - train_loss)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for m in range(len(loaders['X_valid'][1])):\n",
    "\n",
    "\n",
    "            data, target = loaders['X_valid'], loaders['y_valid']\n",
    "            ## update the average validation loss\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data.float())\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.long())\n",
    "            # update average validation loss \n",
    "            valid_loss = valid_loss + (1 / (m + 1)) * (loss.data - valid_loss)\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-5cc9a45475d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train=Variable(torch.from_numpy(X_train))\n",
    "X_valid=Variable(torch.from_numpy(X_valid))\n",
    "y_train=Variable(torch.from_numpy(y_train))\n",
    "y_valid=Variable(torch.from_numpy(y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(80,-1,26)\n",
    "y_train=y_train.reshape(80,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.302332 \tValidation Loss: 2.289289\n",
      "Validation loss decreased (inf --> 2.289289).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 2.301255 \tValidation Loss: 2.237999\n",
      "Validation loss decreased (2.289289 --> 2.237999).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 2.297318 \tValidation Loss: 2.161524\n",
      "Validation loss decreased (2.237999 --> 2.161524).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 2.287112 \tValidation Loss: 2.143605\n",
      "Validation loss decreased (2.161524 --> 2.143605).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 2.272378 \tValidation Loss: 2.127277\n",
      "Validation loss decreased (2.143605 --> 2.127277).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 2.257269 \tValidation Loss: 2.125877\n",
      "Validation loss decreased (2.127277 --> 2.125877).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 2.246855 \tValidation Loss: 2.134461\n",
      "Epoch: 8 \tTraining Loss: 2.240268 \tValidation Loss: 2.125043\n",
      "Validation loss decreased (2.125877 --> 2.125043).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 2.235586 \tValidation Loss: 2.157741\n",
      "Epoch: 10 \tTraining Loss: 2.233083 \tValidation Loss: 2.186530\n",
      "Epoch: 11 \tTraining Loss: 2.231806 \tValidation Loss: 2.211917\n",
      "Epoch: 12 \tTraining Loss: 2.231030 \tValidation Loss: 2.209694\n",
      "Epoch: 13 \tTraining Loss: 2.230851 \tValidation Loss: 2.216269\n",
      "Epoch: 14 \tTraining Loss: 2.230748 \tValidation Loss: 2.216912\n",
      "Epoch: 15 \tTraining Loss: 2.230690 \tValidation Loss: 2.208823\n",
      "Epoch: 16 \tTraining Loss: 2.230638 \tValidation Loss: 2.205256\n",
      "Epoch: 17 \tTraining Loss: 2.230604 \tValidation Loss: 2.205060\n",
      "Epoch: 18 \tTraining Loss: 2.230578 \tValidation Loss: 2.202073\n",
      "Epoch: 19 \tTraining Loss: 2.230551 \tValidation Loss: 2.198109\n",
      "Epoch: 20 \tTraining Loss: 2.230513 \tValidation Loss: 2.193545\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "loaders_scratch = {'X_train':X_train,'X_valid':X_valid,'y_train':y_train,'y_valid':y_valid}\n",
    "model_scratch = train(n_epochs, loaders_scratch, model_scratch, optimizer_scratch,criterion_scratch,save_path= 'model_scratch.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.long>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
